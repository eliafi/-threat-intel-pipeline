# 🛡️ Threat Intelligence Dashboard

An interactive Streamlit dashboard for visualizing threat intelligence data from your S3 pipeline.

## Features

### 📊 **Real-time Data Visualization**
- **Overview Metrics**: Total indicators, unique IPs, domains, and threat tags
- **Timeline Analysis**: Threat detection trends over time
- **Category Breakdown**: Top threat types and geographic distribution
- **Interactive Filtering**: Date ranges, tags, and custom filters

### 🔗 **Seamless Integration** 
- **S3 Integration**: Direct connection to your `threat-intel-data-lake` bucket
- **AWS Credentials**: Uses your existing Airflow AWS connection
- **Docker Ready**: Integrated with your existing Docker compose setup
- **Real-time Updates**: Cached data with automatic refresh

### 🎯 **Advanced Features**
- **File Selection**: Choose from any processed CSV file in S3
- **Export Capability**: Download filtered data as CSV
- **Responsive Design**: Works on desktop and mobile
- **Performance Optimized**: Smart caching and data loading

## Quick Start

### Option 1: Docker (Recommended)

1. **Build and run with your existing setup:**
   ```bash
   docker-compose up -d dashboard
   ```

2. **Access dashboard:**
   - Open http://localhost:8501
   - Dashboard will automatically connect to your S3 bucket

### Option 2: Local Development

1. **Install requirements:**
   ```bash
   cd dashboard
   python run_dashboard.py
   ```

2. **Or manual setup:**
   ```bash
   pip install streamlit pandas plotly boto3
   streamlit run app.py
   ```

## Configuration

The dashboard automatically uses:
- **S3 Bucket**: `threat-intel-data-lake`
- **AWS Region**: `eu-north-1` 
- **AWS Credentials**: Your existing Airflow connection
- **Data Path**: `threat-intel/processed/*.csv`

## Dashboard Sections

### 1. 📁 **Data Selection**
- Lists all available CSV files from your pipeline
- Shows file timestamps and sizes
- Auto-selects most recent data

### 2. 📊 **Overview Metrics**
- Total threat indicators count
- Unique IP addresses found
- Unique domains detected
- Threat tag diversity

### 3. 📈 **Timeline Analysis**
- Interactive line chart of threats over time
- Hover details for specific dates
- Zoom and pan capabilities

### 4. 🏷️ **Threat Categories**
- Bar chart of top 10 threat tags
- Geographic distribution placeholder
- Category filtering options

### 5. 🔍 **Detailed Data View**
- Searchable and sortable data table
- Date range filtering
- Tag-based filtering
- CSV export functionality

## Data Sources

The dashboard reads CSV files generated by your Airflow pipeline:
```
s3://threat-intel-data-lake/
├── threat-intel/
│   └── processed/
│       ├── 2025/08/12/
│       │   ├── otx_pulses_20250812_120000_processed.csv
│       │   └── otx_pulses_20250812_150000_processed.csv
│       └── ...
```

## Why This Approach is Better

### ✅ **Compared to Basic Streamlit:**

1. **Integrated with Your Infrastructure**: Uses your existing AWS connection and S3 setup
2. **Docker Integration**: Seamlessly works with your Airflow environment  
3. **Enhanced Caching**: Smart data loading with TTL-based cache
4. **Production Ready**: Proper error handling and connection management
5. **File Management**: Automatic discovery of all processed files
6. **Advanced Visualizations**: Plotly charts with interactivity

### ✅ **Compared to Other Dashboards:**

1. **Minimal Setup**: No separate database or complex configuration
2. **Python Native**: Leverages your existing Python/Airflow skills
3. **Real-time**: Direct S3 connection with automatic data refresh
4. **Scalable**: Handles large datasets with intelligent caching
5. **Customizable**: Easy to modify and extend with Python

## Troubleshooting

### Dashboard won't start:
- Check if port 8501 is available
- Verify AWS credentials are configured
- Check Docker container logs: `docker-compose logs dashboard`

### No data showing:
- Verify S3 bucket access permissions
- Check if CSV files exist in S3
- Run your Airflow pipeline to generate data

### Connection errors:
- Ensure AWS credentials match your Airflow setup
- Check S3 bucket name and region configuration
- Verify network connectivity to AWS

## Next Steps

1. **Run Your Pipeline**: Execute your `threat_intel_pipeline` DAG in Airflow
2. **Start Dashboard**: `docker-compose up -d dashboard`
3. **View Results**: Open http://localhost:8501
4. **Analyze Threats**: Use interactive filters and visualizations

---

🛡️ **Your complete threat intelligence solution: Airflow → S3 → Streamlit Dashboard**
